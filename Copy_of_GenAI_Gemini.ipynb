{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royarkaofficial/GenAI_OverView_6th_Mon_25/blob/main/Copy_of_GenAI_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB1wFBWVKhnU"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "rk8CMnATLLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text): #accept one argument text , convert\n",
        "    text = text.replace(\".\",\"\\n\") #Bullent point conversion\n",
        "    #text = \"\" + text\n",
        "    return Markdown(textwrap.indent(text,\">\" , predicate= lambda line:True)) #Blockquote formatting , \">\" at the beginning of every line , All lines are indented"
      ],
      "metadata": {
        "id": "kwDX1Dt7LdAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "M9gHAJakMtHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"g\"] = \"AIzaSyBQvFg5JiVliQtJ2zADX6QjLqNLNUh2JbI\""
      ],
      "metadata": {
        "id": "SeXPF8hLN2zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=os.environ[\"g\"])"
      ],
      "metadata": {
        "id": "C3V61v9aOGlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "qyudtoAuOqqn",
        "outputId": "d3bd3cd2-da32-419b-d3d1-61adc3dd4af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-exp-1206\n",
            "models/gemini-exp-1121\n",
            "models/gemini-exp-1114\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/aqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")"
      ],
      "metadata": {
        "id": "WjmuZ0a9O0N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Generate a poem on data testing for ML \")"
      ],
      "metadata": {
        "id": "ugxBGmvgO8UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3lcrFauPKBf",
        "outputId": "a90b3348-54bc-4bc3-b01c-5599a3fef1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"The data flows, a river wide,\\nFrom source unknown, a surging tide.\\nTo train the models, keen and bright,\\nAnd fill their minds with digital light.\\n\\nBut wait! Before you set them free,\\nTo learn and grow, for all to see,\\nA crucial step, you must embrace,\\nData testing, with time and grace.\\n\\nFor hidden flaws, like rocks unseen,\\nCan wreck your model, pure and clean.\\nBias lurking, a subtle beast,\\nCan skew results, a twisted feast.\\n\\nDivide your data, a careful hand,\\nTraining, testing, a separate stand.\\nValidation set, a watchful eye,\\nTo guard against the overfit lie.\\n\\nCheck for outliers, points astray,\\nThat pull the model off its way.\\nMissing values, a gaping void,\\nMust be addressed, or joy destroyed.\\n\\nDistribution shifts, a treacherous slope,\\nWhere training data loses hope.\\nThe real-world's touch, a different tune,\\nCan render models, quite immune.\\n\\nSo test and tune, with diligent care,\\nEvaluate metrics, beyond compare.\\nPrecision, recall, a balancing act,\\nTo build a model, that holds the fact.\\n\\nFor data testing, though unseen, untold,\\nIs worth its weight in digital gold.\\nIt builds the trust, the solid base,\\nFor models strong, in any space. \\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"avg_logprobs\": -0.3052426491174275\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 10,\n",
              "        \"candidates_token_count\": 293,\n",
              "        \"total_token_count\": 303\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "ukgy6oZwPjth",
        "outputId": "97b0c0ca-1424-4dfe-b836-28357ffc915c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">The data flows, a river wide,\n>From source unknown, a surging tide\n>\n>To train the models, keen and bright,\n>And fill their minds with digital light\n>\n>\n>But wait! Before you set them free,\n>To learn and grow, for all to see,\n>A crucial step, you must embrace,\n>Data testing, with time and grace\n>\n>\n>For hidden flaws, like rocks unseen,\n>Can wreck your model, pure and clean\n>\n>Bias lurking, a subtle beast,\n>Can skew results, a twisted feast\n>\n>\n>Divide your data, a careful hand,\n>Training, testing, a separate stand\n>\n>Validation set, a watchful eye,\n>To guard against the overfit lie\n>\n>\n>Check for outliers, points astray,\n>That pull the model off its way\n>\n>Missing values, a gaping void,\n>Must be addressed, or joy destroyed\n>\n>\n>Distribution shifts, a treacherous slope,\n>Where training data loses hope\n>\n>The real-world's touch, a different tune,\n>Can render models, quite immune\n>\n>\n>So test and tune, with diligent care,\n>Evaluate metrics, beyond compare\n>\n>Precision, recall, a balancing act,\n>To build a model, that holds the fact\n>\n>\n>For data testing, though unseen, untold,\n>Is worth its weight in digital gold\n>\n>It builds the trust, the solid base,\n>For models strong, in any space\n> \n"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}